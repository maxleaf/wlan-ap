From 912b4850b080c013dd8df6439b6a3d1a4446065a Mon Sep 17 00:00:00 2001
From: Balamurugan Mahalingam <quic_bmahalin@quicinc.com>
Date: Fri, 18 Nov 2022 04:38:02 -0800
Subject: [PATCH 2/4] ath12k: Remove locks while accessing descriptors

Each core has its own tx sw descriptors pools. No locks are needed to
access sw descriptor pools

Optimize ring selection operation

Signed-off-by: Balamurugan Mahalingam <quic_bmahalin@quicinc.com>

--- a/drivers/net/wireless/ath/ath12k/dp_tx.c
+++ b/drivers/net/wireless/ath/ath12k/dp_tx.c
@@ -90,26 +90,6 @@ struct ath12k_tx_desc_info *ath12k_dp_tx
 	return desc;
 }
 
-static struct ath12k_tx_desc_info *ath12k_dp_tx_assign_buffer(struct ath12k_dp *dp,
-							      u8 ring_id)
-{
-	struct ath12k_tx_desc_info *desc = NULL;
-
-	spin_lock_bh(&dp->tx_desc_lock[ring_id]);
-	desc = list_first_entry_or_null(&dp->tx_desc_free_list[ring_id],
-					struct ath12k_tx_desc_info,
-					list);
-	if (unlikely(!desc)) {
-		spin_unlock_bh(&dp->tx_desc_lock[ring_id]);
-		ath12k_warn(dp->ab, "failed to allocate data Tx buffer\n");
-		return NULL;
-	}
-
-	list_move_tail(&desc->list, &dp->tx_desc_used_list[ring_id]);
-	spin_unlock_bh(&dp->tx_desc_lock[ring_id]);
-
-	return desc;
-}
 
 static void ath12k_hal_tx_cmd_ext_desc_setup(struct ath12k_base *ab, void *cmd,
 					     struct hal_tx_info *ti)
@@ -265,13 +245,13 @@ int ath12k_dp_tx(struct ath12k *ar, stru
 	    !ieee80211_is_data(hdr->frame_control)))
 		return -ENOTSUPP;
 
-	ti.ring_id = smp_processor_id() % DP_TCL_NUM_RING_MAX;
+	ti.ring_id = smp_processor_id();
 
 	ti.rbm_id = ab->hal.ops->tcl_to_wbm_rbm_map[ti.ring_id].rbm_id;
 
 	tx_ring = &dp->tx_ring[ti.ring_id];
 
-	tx_desc = ath12k_dp_tx_assign_buffer(dp, ti.ring_id);
+	tx_desc = ath12k_dp_tx_assign_buffer_nolock(dp, ti.ring_id);
 	if (unlikely(!tx_desc)) {
 		ab->soc_stats.tx_err.txbuf_na[ti.ring_id]++;
 		return -ENOSPC;
@@ -398,18 +378,14 @@ int ath12k_dp_tx(struct ath12k *ar, stru
 	hal_ring_id = tx_ring->tcl_data_ring.ring_id;
 	tcl_ring = &ab->hal.srng_list[hal_ring_id];
 
-	spin_lock_bh(&tcl_ring->lock);
-
-	ath12k_hal_srng_access_begin(ab, tcl_ring);
-
+	ath12k_hal_srng_access_src_ring_begin_nolock(ab, tcl_ring);
 	hal_tcl_desc = (void *)ath12k_hal_srng_src_get_next_entry(ab, tcl_ring);
 	if (unlikely(!hal_tcl_desc)) {
 		/* NOTE: It is highly unlikely we'll be running out of tcl_ring
 		 * desc because the desc is directly enqueued onto hw queue.
 		 */
-		ath12k_hal_srng_access_end(ab, tcl_ring);
+		ath12k_hal_srng_access_umac_src_ring_end_nolock(ab->mem, tcl_ring);
 		ab->soc_stats.tx_err.desc_na[ti.ring_id]++;
-		spin_unlock_bh(&tcl_ring->lock);
 		ret = -ENOMEM;
 
 		goto fail_unmap_dma_ext_desc;
@@ -437,9 +413,7 @@ int ath12k_dp_tx(struct ath12k *ar, stru
 	tcl_cmd->info4 = arvif->desc.info4;
 	tcl_cmd->info5 = 0;
 
-	ath12k_hal_srng_access_end(ab, tcl_ring);
-
-	spin_unlock_bh(&tcl_ring->lock);
+	ath12k_hal_srng_access_umac_src_ring_end_nolock(ab->mem, tcl_ring);
 
 	ath12k_dbg_dump(ab, ATH12K_DBG_DP_TX, NULL, "dp tx msdu: ",
 			skb->data, skb->len);
