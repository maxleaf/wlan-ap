From 2109b3b94031d414446ef0bc7672f86a663edfb0 Mon Sep 17 00:00:00 2001
From: Balamurugan Mahalingam <quic_bmahalin@quicinc.com>
Date: Wed, 23 Nov 2022 20:08:21 -0800
Subject: [PATCH] ath12k: Enable fast recycling the skbs for performance and
 desc prefetch

The SKB fast recycling features reduces the cpu overhead by quickly
returning the skb list to the per cpu recycler pool and also
provides information to driver for handling dma cache invalidation
operations in a efficient way

Signed-off-by: Balamurugan Mahalingam <quic_bmahalin@quicinc.com>
---
 drivers/net/wireless/ath/ath12k/dp.h    |  1 +
 drivers/net/wireless/ath/ath12k/dp_tx.c | 20 ++++++++++++++++++--
 2 files changed, 19 insertions(+), 2 deletions(-)

--- a/drivers/net/wireless/ath/ath12k/dp.h
+++ b/drivers/net/wireless/ath/ath12k/dp.h
@@ -321,6 +321,7 @@ struct ath12k_tx_desc_info {
 	u32 desc_id; /* Cookie */
 	u8 mac_id;
 	u8 pool_id;
+	u8 recycler_fast_xmit;
 };
 
 struct ath12k_spt_info {
--- a/drivers/net/wireless/ath/ath12k/dp_tx.c
+++ b/drivers/net/wireless/ath/ath12k/dp_tx.c
@@ -86,6 +86,7 @@ struct ath12k_tx_desc_info *ath12k_dp_tx
 	}
 
 	list_move_tail(&desc->list, &dp->tx_desc_used_list[pool_id]);
+	prefetch(desc);
 
 	return desc;
 }
@@ -145,6 +146,12 @@ int ath12k_dp_tx_direct(struct ath12k_vi
 
 	tx_desc->skb = skb;
 	tx_desc->mac_id = arvif->pdev_idx;
+	tx_desc->recycler_fast_xmit = 0;
+
+	/* the edma driver uses this flags to optimize the cache invalidation */
+	skb->fast_recycled = 1;
+	if (skb->is_from_recycler)
+		tx_desc->recycler_fast_xmit = 1;
 
 	skb_cb->vif = arvif->vif;
 	skb_cb->paddr =  paddr;
@@ -320,6 +327,7 @@ int ath12k_dp_tx(struct ath12k *ar, stru
 
 	tx_desc->skb = skb;
 	tx_desc->mac_id = ar->pdev_idx;
+	tx_desc->recycler_fast_xmit = 0;
 	ti.desc_id = tx_desc->desc_id;
 	ti.data_len = skb->len;
 	skb_cb->paddr = ti.paddr;
@@ -841,6 +849,8 @@ int ath12k_dp_tx_completion_handler(stru
 	struct hal_wbm_completion_ring_tx *tx_status;
 	enum hal_wbm_rel_src_module buf_rel_source;
 	enum hal_wbm_tqm_rel_reason rel_status;
+	struct sk_buff_head free_list_head;
+	int recycler_fast_xmit;
 
 
 	ath12k_hal_srng_access_dst_ring_begin_nolock(ab, status_ring);
@@ -852,6 +862,7 @@ int ath12k_dp_tx_completion_handler(stru
 	}
 
 	ath12k_hal_srng_dst_invalidate_entry(ab, status_ring, valid_entries);
+	skb_queue_head_init(&free_list_head);
 
 	while (budget && (tx_status = ath12k_hal_srng_dst_get_next_cache_entry(ab, status_ring))) {
 		if (!ath12k_dp_tx_completion_valid(tx_status))
@@ -876,6 +887,7 @@ int ath12k_dp_tx_completion_handler(stru
 
 		msdu = tx_desc->skb;
 		mac_id = tx_desc->mac_id;
+		recycler_fast_xmit = tx_desc->recycler_fast_xmit;
 		skb_ext_desc = tx_desc->skb_ext_desc;
 		/* Release descriptor as soon as extracting necessary info
 		 * to reduce contention
@@ -892,6 +904,7 @@ int ath12k_dp_tx_completion_handler(stru
 		}
 		budget--;
 
+		ar = ab->pdevs[mac_id].ar;
 		if (atomic_dec_and_test(&ar->dp.num_tx_pending))
 			wake_up(&ar->dp.tx_empty_waitq);
 
@@ -922,9 +935,12 @@ int ath12k_dp_tx_completion_handler(stru
 				kfree_skb_list(skb_shinfo(msdu)->frag_list);
 				skb_shinfo(msdu)->frag_list = NULL;
 			}
-			dev_kfree_skb(msdu);
+			if (likely(recycler_fast_xmit)) {
+				__skb_queue_head(&free_list_head, msdu);
+			} else {
+				dev_kfree_skb(msdu);
+			}
 		} else {
-			ar = ab->pdevs[mac_id].ar;
 
 			ath12k_dp_tx_complete_msdu(ar, msdu, tx_status,
 						   buf_rel_source,
@@ -933,6 +949,7 @@ int ath12k_dp_tx_completion_handler(stru
 	}
 
 	ath12k_hal_srng_access_umac_dst_ring_end_nolock(ab->mem, status_ring);
+	dev_kfree_skb_list_fast(&free_list_head);
 
 	return (orig_budget - budget);
 }
